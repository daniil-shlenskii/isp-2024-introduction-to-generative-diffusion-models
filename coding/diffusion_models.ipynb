{"cells":[{"cell_type":"markdown","metadata":{"id":"5ZXJoDiD_x-N"},"source":["# Diffusion models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZzUKCFsKhAv"},"outputs":[],"source":["!wget --quiet --show-progress -O utils.py \"https://raw.githubusercontent.com/daniil-shlenskii/isp-2024-introduction-to-generative-diffusion-models/main/coding/utils.py\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grmP96FjfQZg"},"outputs":[],"source":["import os\n","import re\n","import random\n","\n","import numpy as np\n","import seaborn as sns\n","import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_swiss_roll\n","from sklearn.utils import shuffle\n","from tqdm import tqdm\n","from copy import deepcopy\n","from typing import Optional, Tuple, List\n","\n","from utils import get_labeled_data_loader, MyUNet\n","\n","\n","MODELS_DIR = \"models\"\n","if not os.path.exists(MODELS_DIR):\n","    os.mkdir(MODELS_DIR)\n","SAVE_DPPM_SWISS_PATH = f\"{MODELS_DIR}/ddpm_swiss.pt\"\n","SAVE_DPPM_CFG_SWISS_PATH = f\"{MODELS_DIR}/ddpm_cfg_swiss.pt\"\n","SAVE_DPPM_MNIST_PATH = f\"{MODELS_DIR}/ddpm_mnist.pt\"\n","SAVE_DPPM_CFG_MNIST_PATH = f\"{MODELS_DIR}/ddpm_cfg_mnist.pt\""]},{"cell_type":"markdown","metadata":{"id":"QRFti0_GCRpD"},"source":["## DDPM"]},{"cell_type":"markdown","metadata":{"id":"i8vx6pxgCqBv"},"source":["In this part you have to implement your own diffusion model (DDPM) and apply it to SwissRoll dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hHFI7vQSKYj2"},"outputs":[],"source":["def make_swiss_dataset(num_samples):\n","    X0, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n","    X1, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n","    X0 = X0[:, [0, 2]]\n","    X1 = X1[:, [0, 2]]\n","    X1 = -X1\n","    X, y = shuffle(\n","        np.concatenate([X0, X1], axis=0),\n","        np.concatenate([np.zeros(len(X0)), np.ones(len(X1))], axis=0),\n","        random_state=0)\n","    X = (X - X.mean(axis=0)) / X.std(axis=0)\n","\n","    return X, y\n","\n","X, y = make_swiss_dataset(2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utJXK-lZKYj3"},"outputs":[],"source":["plt.figure(figsize=(4, 4))\n","sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y);"]},{"cell_type":"markdown","metadata":{"id":"bbKDiZ51Cp9U"},"source":["**Quick recap of diffusion models theory**"]},{"cell_type":"markdown","metadata":{"id":"2TAClXs_Cp5O"},"source":["Diffusion model consists of forward and backward processes.\n","\n","Forward process is defined as a posterior distribution $q(x_{1:T}|x_0)$.\n","\n","It is also a Markov chain, which consequently add gaussian noise to a given object $x_0$.\n","\n","On every step noise is added with a different magnitude, which is determined with a schedule of variances $\\{\\beta_1, ... \\beta_T\\}$.\n","\n","If this schedule is chosen properly and T goes to infinity (or is large enough), we are to converge to pure noise $\\mathcal{N}(0, I)$.\n","\n","Distributions $q$ have the following view:\n","$$\n"," q(x_t | x_{t - 1}) := \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t - 1}, \\beta_tI), \\ \\ \\ \\ \\ \\ \\ q(x_{1:T}|x_0) = \\prod_{t = 1}^T q(x_t | x_{t - 1})\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"e7tdIbQEFv0Q"},"source":["Now let's take a look of a backward process.\n","\n","Backward process consequently denoise pure gaussian noise until the object from the original distribution is gotten.\n","\n","So a diffusion model is a probability model with latent variables\n","$p_\\theta(x_0) := \\int p_\\theta(x_{0:T}) dx_{1:T}$,\n","where latents $x_1, ..., x_T$ correspond to noised objects and $x_0$ is an object from an original distribution.\n","\n","Joint distribution $p_\\theta(x_{0:T})$ is called the backward diffusion process, which is essentially a Markov chain of gaussian distributions\n","$p_\\theta(x_{i-1}|x_{i})$:\n","\n","$$\n","p(x_{0:T}) = p(x_T) \\prod_{t = 1}^Tp_{\\theta}(x_{t-1}|x_t) \\ \\ \\ \\ \\ \\ \\ \\ \\ p_\\theta(x_{T})=\\mathcal{N}(x_T | 0, I)\n","$$\n","$$\n","  p_{\\theta}(x_{t - 1}|x_t):= \\mathcal{N}(x_{t - 1}; \\mu_{\\theta}(x_t, t), \\Sigma_{\\theta}(x_t, t))\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"utLEiQ7UInk6"},"source":["Let's back to the distribution $q(x_t | x_{t - 1})$.\n","\n","In order to get $x_t$ we have to compute $x_1, ..., x_{t - 1}$ iteratively.\n","\n","Though due to properties of the gaussian distriubtion it can be done more efficiently.\n","\n","Let's denote\n","$\\alpha_t := 1- \\beta_t$ Ð¸ $\\bar{\\alpha}_t:= \\prod_{i = 1}^t\\alpha_i$.\n","\n","Then\n","$$\n","q(x_t | x_0) = \\mathcal{N}(x_t;\\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha}_t)I) \\quad \\quad \\quad \\quad \\quad \\quad (1)\n","$$\n","\n","So a model can be trained then by optimizing the individual terms of the sum of the variational lower bound:\n","$$\n","L_{VLB} = \\mathbb{E}_q [\\underbrace{D_\\text{KL}(q(\\mathbf{x}_T |\n","\\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T))}_{L_T} + \\sum_{t=2}^T\n","\\underbrace{D_\\text{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t,\n","\\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1}\n","| \\mathbf{x}_t))}_{L_{t-1}} \\underbrace{- \\log p_\\theta(\\mathbf{x}_0\n","| \\mathbf{x}_1)}_{L_0}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"FEZ__C82KlzL"},"source":["For training you just have to write down the following distribution $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $:\n","\n","$$\n","    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 \\ \\ \\ \\ \\ \\ (2)\n","$$\n","$$\n","    \\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t  \\quad \\quad \\quad \\quad \\quad \\quad \\quad (3)\n","$$\n","\n","\n","Follow the link to find details [Denoising Diffusion Probabilistic Models (Ho et al. 2020)](https://arxiv.org/abs/2006.11239).\n","\n","Nevertheless, in this paper was shown, that training with a simpler loss, you'll get better results.\n","\n","Recall that\n","$$\n","x_t(x_0, \\epsilon) = \\sqrt{\\bar{\\alpha}_t} x_0 +  \\sqrt{(1-\\bar{\\alpha}_t)}\\epsilon, \\ \\ \\ \\epsilon \\sim \\mathcal{N}(0, I) \\quad \\quad \\quad \\quad \\quad \\quad \\quad (4)\n","$$\n","\n","Let our model predict $\\epsilon$ from equality above, training by optimizing a following loss:\n","\n","$$L^{simple}_t = \\mathbb{E}_{x_0, \\epsilon, t}\\bigg[ \\|\\epsilon - \\epsilon_{\\theta}(x_t, t)\\|^2\\bigg]$$\n","\n","This loss will be used in this task.\n","\n","In order to sample (backward process), we have to get\n","$\\mu_{\\theta}(x_t, x_0)$ from $\\epsilon_{\\theta}(x_t, t)$.\n","\n","To do that find $\\hat{x}_0(\\epsilon_{\\theta}, x_t)$ from the eq (4) and\n","substitute it to eq (2).\n","\n","_____"]},{"cell_type":"markdown","metadata":{"id":"PdzUNQgRQA9Q"},"source":["**Now to the task**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VwXNzi6fQZm"},"outputs":[],"source":["# it's just an utility function. basically, returns arr[timesteps], where timesteps are indices. (look at class Diffusion)\n","def _extract_into_tensor(arr: th.Tensor, timesteps: th.Tensor, broadcast_shape: Tuple):\n","    \"\"\"\n","    Extract values from a 1-D torch tensor for a batch of indices.\n","    :param arr: 1-D torch tensor.\n","    :param timesteps: a tensor of indices to extract from arr.\n","    :param broadcast_shape: a larger shape of K dimensions with the batch\n","                            dimension equal to the length of timesteps.\n","    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n","    \"\"\"\n","    res = arr.to(device=timesteps.device)[timesteps].float()\n","    while len(res.shape) < len(broadcast_shape):\n","        res = res[..., None]\n","    return res.expand(broadcast_shape)"]},{"cell_type":"markdown","metadata":{"id":"8Yitcw9iQd1x"},"source":["### DDPM class\n","\n","It consists of\n","- ForwardDiffusion class\n","- BackwardDiffusion clas\n","- Model predicting noise\n","\n","You are to fill in the gaps marked with `your code`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzF48wz2KYj9"},"outputs":[],"source":["def get_beta_schedule(num_diffusion_timesteps: int) -> th.Tensor:\n","    scale = 1000 / num_diffusion_timesteps\n","    beta_start = scale * 0.0001\n","    beta_end = scale * 0.02\n","    betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n","    betas = th.from_numpy(betas).double()\n","    return betas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PjMp4WcKYj9"},"outputs":[],"source":["class BaseDiffusion:\n","    def __init__(self, betas: th.Tensor) -> None:\n","        self.betas = betas\n","        self.alphas = 1 - self.betas\n","        self.alphas_cumprod = th.cumprod(self.alphas, dim=-1)\n","        self.num_timesteps = len(self.betas)\n","\n","basediff = BaseDiffusion(get_beta_schedule(20))\n","basediff.alphas_cumprod"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOlDmHU1KYj-"},"outputs":[],"source":["class ForwardDiffusion(BaseDiffusion):\n","    def q_mean_variance(self, x0: th.Tensor, t: th.Tensor) -> th.Tensor:\n","        # ====\n","        # your code\n","        # calculate mean and variance of the distribution q(x_t | x_0) (use equation (1))\n","        ...\n","        # ====\n","        return mean, variance\n","\n","    def q_sample(self, x0: th.Tensor, t: th.Tensor, noise: Optional[th.Tensor]=None) -> th.Tensor:\n","        # ====\n","        # your code\n","        # sample from the distribution q(x_t | x_0) (use equation (1))\n","        ...\n","        # ====\n","        return samples"]},{"cell_type":"markdown","metadata":{"id":"6X0sz28AKYj-"},"source":["Let's take a look on how our data is noised with $t$ increasing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geh9uJPnKYj-"},"outputs":[],"source":["T = 100\n","forward_diffusion = ForwardDiffusion(get_beta_schedule(T))\n","\n","plot_n_steps = 8\n","noise_n_steps = 3\n","\n","_, axs = plt.subplots(1, plot_n_steps, figsize=(plot_n_steps * 4, 4))\n","t_to_plot = list(np.round(np.linspace(forward_diffusion.num_timesteps - 1, 15, num=noise_n_steps)).astype(\"int\")) + \\\n","            list(np.round(np.linspace(10, 0, num=plot_n_steps - noise_n_steps)).astype(\"int\"))\n","t_to_plot = t_to_plot[::-1]\n","for i,t in enumerate(t_to_plot):\n","    x = forward_diffusion.q_sample(\n","        x0=th.from_numpy(X),\n","        t=th.ones_like(th.from_numpy(y)).long() * t,\n","    )\n","    sns.scatterplot(x=x[:,0], y=x[:,1], hue=y, ax=axs[i])\n","    axs[i].set(title=t)"]},{"cell_type":"markdown","metadata":{"id":"nuBQQw19KYj_"},"source":["**How to understand if we took T large enough?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wrknNLVyR5HB"},"outputs":[],"source":["class ReverseDiffusion(BaseDiffusion):\n","    def __init__(self, *args, clip_x0: Optional[bool]=False, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.alphas_cumprod_prev = th.cat(\n","            [th.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n","        )\n","\n","        # ====\n","        # your code\n","        # calculate variance of the distribution q(x_{t-1} | x_t, x_0) mean (use equation (3))\n","        self.variance = ...\n","        # ====\n","\n","        # ====\n","        # your code\n","        # calculate coefficients of the distribution q(x_{t-1} | x_t, x_0) mean (use equation (2))\n","        self.xt_coef = ...\n","        self.x0_coef = ...\n","        # ====\n","\n","        self.clip_x0 = clip_x0\n","\n","    def get_x0(self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor) -> th.Tensor:\n","        # ====\n","        # your code\n","        # get x_0 (use equations (4) and (2))\n","        ...\n","        # ====\n","        if self.clip_x0:\n","            x0 = x0.clamp(-1., 1.)\n","        return x0\n","\n","    def q_posterior_mean_variance(\n","        self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor\n","    ) -> Tuple[th.Tensor, th.Tensor]:\n","        # ====\n","        # your code\n","        # get mean and variance of the distribution q(x_{t-1} | x_t, x_0) mean (use equations (2) and (3))\n","        ...\n","        # ====\n","        return mean, variance\n","\n","    def p_sample(self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor) -> th.Tensor:\n","        # read this code carefully\n","        mean, variance = self.q_posterior_mean_variance(xt=xt, eps=eps, t=t)\n","        noise = th.randn_like(xt, device=xt.device)\n","\n","        nonzero_mask = th.ones_like(t)  # to not add any noise while predicting x0\n","        nonzero_mask[t == 0] = 0\n","        nonzero_mask = _extract_into_tensor(\n","            nonzero_mask, th.arange(nonzero_mask.shape[0]), xt.shape\n","        )\n","        nonzero_mask = nonzero_mask.to(xt.device)\n","        sample = mean + nonzero_mask * variance.sqrt() * noise\n","        return sample.float()"]},{"cell_type":"markdown","metadata":{"id":"GIJucKg8KYkA"},"source":["### Model for noise prediction\n","\n","Now we have to implement model with weights $\\theta$, which parametrize backward process.\n","\n","Model should not be complex, just several linear layers are enough.\n","\n","Don't forget to take into account classes $y$ and timesteps $t$.\n","\n","Model is supposed to predict noise $\\epsilon$: $\\epsilon_\\theta(x_t, t, y)$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCwgtBWAKYkA"},"outputs":[],"source":["class ConditionalMLP(nn.Module):\n","    def __init__(self, d_in: int, T: int, n_classes: int, hidden_dim: Optional[int]=128):\n","        super().__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.x_proj = nn.Linear(d_in, self.hidden_dim)\n","        self.t_proj = nn.Embedding(T, self.hidden_dim)\n","        self.y_embed = nn.Embedding(n_classes, self.hidden_dim)\n","        self.backbone = nn.Sequential(\n","            nn.Linear(self.hidden_dim, 2 * self.hidden_dim),\n","            nn.GELU(),\n","            nn.Linear(2 * self.hidden_dim, d_in)\n","        )\n","\n","    @property\n","    def device(self):\n","        return next(self.parameters()).device\n","\n","    def forward(self, x, t, y):\n","        '''\n","        :x input, e.g. images\n","        :t 1d th.gTensor of timesteps\n","        :y 1d th.LongTensor of class labels\n","        '''\n","        x = self.x_proj(x)\n","        t = self.t_proj(t.int())\n","        y = self.y_embed(y)\n","        x = x + t + y\n","        x = F.gelu(x)\n","        return self.backbone(x)"]},{"cell_type":"markdown","metadata":{"id":"nUDWUsP8KYkB"},"source":["Let's unite all implemented entities in the DDPM class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw6vueDnTt7C"},"outputs":[],"source":["class DDPM(nn.Module):\n","    def __init__(\n","        self,\n","        betas: th.Tensor,\n","        model: nn.Module,\n","        clip_x0: Optional[bool] = False,\n","        shape: Optional[th.Tensor] = None,\n","        update_ema_after: Optional[int] = 2000,\n","    ) -> None:\n","        super().__init__()\n","\n","        self.forward_diffusion = ForwardDiffusion(betas=betas)\n","        self.reverse_diffusion = ReverseDiffusion(betas=betas, clip_x0=clip_x0)\n","        self.model = model\n","        self.num_timesteps = len(betas)\n","\n","        self.ema = deepcopy(model)\n","        self.update_ema_after = update_ema_after\n","        self.ema_counter = 0\n","\n","        self.register_buffer(\"betas\", betas)\n","        self.register_buffer(\"clip_x0\", th.tensor(clip_x0, dtype=bool))\n","        self.register_buffer(\"shape\", shape)\n","\n","    @property\n","    def device(self) -> None:\n","        return next(self.parameters()).device\n","\n","    @th.no_grad()\n","    def sample(self, y: th.Tensor) -> th.Tensor:\n","        assert self.shape is not None\n","        if self.ema_counter < self.update_ema_after:\n","            model = self.model\n","        else:\n","            model = self.ema\n","\n","        num_samples = y.shape[0]\n","        x = th.randn((num_samples, *self.shape), device=self.device, dtype=th.float32)\n","        indices = list(range(self.num_timesteps))[::-1]\n","\n","        for i in tqdm(indices):\n","            t = th.tensor([i] * num_samples, device=x.device)\n","            # ====\n","            # your code\n","            # 1) get epsilon from the model\n","            # 2) sample from the reverse diffusion\n","            eps = ...\n","            x = ...\n","            # ====\n","        return x, y\n","\n","    def train_loss(self, x0: th.Tensor, y: th.Tensor) -> th.Tensor:\n","        self._update_ema()\n","        if self.shape is None:\n","            self.shape = th.tensor(list(x0.shape)[1:], device=\"cpu\")\n","        t = th.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n","        noise = th.randn_like(x0)\n","\n","        # ====\n","        # your code\n","        # 1) get x_t\n","        # 2) get epsilon from the model\n","        x_t = ...\n","        eps = ...\n","        # ====\n","        loss = F.mse_loss(eps, noise)\n","        return loss\n","\n","    def _update_ema(self):\n","        self.ema_counter += 1\n","        if self.ema_counter < self.update_ema_after:\n","            return\n","        if self.ema_counter == self.update_ema_after:\n","            self.ema.load_state_dict(self.model.state_dict())\n","\n","        ema_weight = 0.99\n","        new_ema_state_dict = self.ema.state_dict()\n","        model_state_dict = self.model.state_dict()\n","        for key, val in new_ema_state_dict.items():\n","            if isinstance(val, th.Tensor):\n","                new_ema_state_dict[key] = (\n","                    ema_weight * new_ema_state_dict[key] +\n","                    (1 - ema_weight) * model_state_dict[key]\n","                )\n","        self.ema.load_state_dict(new_ema_state_dict)\n","\n","    @classmethod\n","    def from_pretrained(cls: \"DDPM\", model: nn.Module, ckpt_path: str) -> \"DDPM\":\n","        ckpt = th.load(ckpt_path)\n","        model_state_dict = {\n","            re.sub(\"ema.\", \"\", re.sub(\"model.\", \"\", key)):\n","            val for key, val in ckpt.items() if \"ema.\" in key\n","        }\n","        model.load_state_dict(model_state_dict)\n","        return cls(\n","            betas=ckpt[\"betas\"],\n","            model=model,\n","            clip_x0=ckpt[\"clip_x0\"],\n","            shape=ckpt[\"shape\"],\n","        )"]},{"cell_type":"markdown","metadata":{"id":"HqtB_us0KYkD"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZVK8_rKKYkD"},"outputs":[],"source":["def train_model(\n","    ddpm: DDPM,\n","    dataloader: DataLoader,\n","    lr: float,\n","    weight_decay: float,\n","    n_iters: int,\n","    device: str = \"cpu\",\n","    log_every: int = 500\n","):\n","    ddpm = ddpm.to(device)\n","\n","    optimizer = th.optim.AdamW(\n","        ddpm.model.parameters(), lr=lr, weight_decay=weight_decay\n","    )\n","    step = 0\n","    curr_loss_gauss = 0.0\n","    curr_count = 0\n","    optimizer.zero_grad()\n","    data_iter = iter(dataloader)\n","    while step < n_iters:\n","        try:\n","            batch = next(data_iter)\n","        except StopIteration:\n","            data_iter = iter(dataloader)\n","            batch = next(data_iter)\n","        x, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n","\n","        loss = ddpm.train_loss(x, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        curr_count += len(x)\n","        curr_loss_gauss += loss.item() * len(x)\n","\n","        if (step + 1) % log_every == 0:\n","            gloss = np.around(curr_loss_gauss / curr_count, 4)\n","            print(f\"Step {(step + 1)}/{n_iters} Loss: {gloss}\")\n","            curr_count = 0\n","            curr_loss_gauss = 0.0\n","\n","        step += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ijiAy6pUvkn"},"outputs":[],"source":["T = 100\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE = 1024\n","LR = 0.01\n","WEIGHT_DECAY = 0.0\n","N_ITERS = 15000\n","# ====\n","\n","model = ConditionalMLP(d_in=2, T=T, n_classes=2)\n","device = \"cpu\" # cpu is enough\n","\n","if not os.path.exists(SAVE_DPPM_SWISS_PATH):\n","    th.manual_seed(0)\n","    random.seed(0)\n","\n","    ddpm = DDPM(betas=get_beta_schedule(T), model=model)\n","    dataloader = get_labeled_data_loader(X, y, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    train_model(\n","        ddpm=ddpm,\n","        dataloader=dataloader,\n","        lr=LR,\n","        weight_decay=WEIGHT_DECAY,\n","        n_iters=N_ITERS,\n","        device=device\n","    )\n","    th.save(ddpm.to(\"cpu\").state_dict(), SAVE_DPPM_SWISS_PATH)\n","else:\n","    ddpm = DDPM.from_pretrained(model, SAVE_DPPM_SWISS_PATH)\n","\n","_ = ddpm.to(device)"]},{"cell_type":"markdown","metadata":{"id":"h6RMOjHZKYkF"},"source":["Now let's take a look on a data our model learned to generate."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIpi8oT5KYkG"},"outputs":[],"source":["num_samples = X.shape[0]\n","ys = th.randint(0, 2, size=(num_samples,), device=device)\n","Xs, ys = ddpm.sample(ys)\n","plt.figure(figsize=(4, 4))\n","sns.scatterplot(x=Xs[:, 0], y=Xs[:, 1], hue=ys)"]},{"cell_type":"markdown","metadata":{"id":"5RSpn0XJU_G9"},"source":["Let's look at the denoising process"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOPJA-5KKbyv"},"outputs":[],"source":["x = th.randn(y.shape[0], 2, requires_grad=False)\n","y = th.tensor(y, requires_grad=False, dtype=th.long)\n","\n","plot_n_steps = 8\n","noise_n_steps = 3\n","_, axs = plt.subplots(1, plot_n_steps, figsize=(plot_n_steps * 4, 4))\n","\n","idx = 0\n","t_to_plot = list(np.round(np.linspace(ddpm.num_timesteps - 1, 15, num=noise_n_steps)).astype(\"int\")) + \\\n","            list(np.round(np.linspace(10, 0, num=plot_n_steps - noise_n_steps)).astype(\"int\"))\n","for i in tqdm(range(ddpm.num_timesteps - 1, -1, -1)):\n","    t = th.tensor(i, dtype=th.long, requires_grad=False).expand(x.shape[0])\n","    with th.no_grad():\n","        eps = ddpm.model(x, t, y)\n","        x =  ddpm.reverse_diffusion.p_sample(x, eps, t)\n","    if i in t_to_plot:\n","        sns.scatterplot(x=x[:,0], y=x[:,1], hue=y, ax=axs[idx])\n","        axs[idx].set(title=i)\n","        idx += 1"]},{"cell_type":"markdown","metadata":{"id":"qL9JaHiYKYkI"},"source":["### MNIST\n","\n","Now we will apply diffusion model to the MNIST dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCVyL00kPTB3"},"outputs":[],"source":["from torchvision.datasets.mnist import MNIST\n","\n","def mnist_to_train_range(X):\n","    return ((X.astype(\"float32\") / 255.) - 0.5) * 2\n","\n","def mnist_from_train_range(X):\n","    return (((X.astype(\"float32\") + 1.0) / 2) * 255.).astype(\"int\")\n","\n","dataset = MNIST(\"./datasets\", download=True, train=True)\n","X = dataset.data.numpy().astype(\"float32\")[:, None]\n","y = dataset.targets.numpy()\n","mnist_loader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"CtbW7kBnKYkK"},"source":["Let's plot several instances of the given dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYVjjK6BgooE"},"outputs":[],"source":["def show_images(images, ys, title=\"\"):\n","    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n","\n","    # Converting images to CPU numpy arrays\n","    if type(images) is th.Tensor:\n","        images = images.detach().cpu().numpy()\n","        ys = ys.detach().cpu().numpy()\n","\n","    # Defining number of rows and columns\n","    rows = int(len(images) ** (1 / 2))\n","    cols = round(len(images) / rows)\n","    fig = plt.figure(figsize=(cols*2, rows*2))\n","\n","    # Populating figure with sub-plots\n","    idx = 0\n","    for r in range(rows):\n","        for c in range(cols):\n","            fig.add_subplot(rows, cols, idx + 1)\n","\n","            if idx < len(images):\n","                plt.imshow(images[idx][0], cmap=\"gray\")\n","                plt.title(f\"{int(ys[idx])}\")\n","                plt.tick_params(bottom = False, labelbottom=False)\n","                idx += 1\n","    fig.suptitle(title, fontsize=30)\n","\n","    # Showing the figure\n","    plt.show()\n","\n","def show_first_batch(loader, batch_size=16):\n","    for batch in loader:\n","        show_images(batch[\"x\"][:batch_size], batch[\"y\"][:batch_size], \"Images in the first batch\")\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFhOvS0PPZoe"},"outputs":[],"source":["show_first_batch(mnist_loader)"]},{"cell_type":"markdown","metadata":{"id":"tVljzKQbKYkM"},"source":["Let's take a look on the forward process for the MNIST images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10tMXiU8P_6v"},"outputs":[],"source":["forward_diffusion = ForwardDiffusion(betas=get_beta_schedule(1000))\n","plot_n_steps = 9\n","\n","images = next(iter(mnist_loader))[\"x\"][:1, 0]\n","\n","_, axs = plt.subplots(1, plot_n_steps, figsize=(6 * plot_n_steps, 6))\n","t_to_plot = list(np.round(np.linspace(0, forward_diffusion.num_timesteps - 1, num=plot_n_steps)).astype(\"int\"))\n","for i,t in enumerate(t_to_plot):\n","    x = forward_diffusion.q_sample(\n","        x0=images,\n","        t=(th.ones(images.shape[0], device=images.device) * t).long(),\n","    )\n","    axs[i].imshow(x[0], cmap=\"gray\")\n","    axs[i].set(title=t)"]},{"cell_type":"markdown","metadata":{"id":"1m6162FnKYkN"},"source":["Noise predicting model is written for you.\n","\n","You can find details in the attached `utils.py` file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0DV74a7mPUgO"},"outputs":[],"source":["# Downloading pretrained model\n","!gdown -O \"models/ddpm_mnist.pt\" \"https://drive.google.com/uc?id=1fSPB08M6aBNmhjRgSn3qpdq5hXl1Xhao\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4foGURhyRAaG"},"outputs":[],"source":["T = 1000\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE = 1024\n","LR = 0.01\n","WEIGHT_DECAY = 0.0\n","N_ITERS = 5000\n","# ====\n","\n","model = MyUNet()\n","device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n","\n","if not os.path.exists(SAVE_DPPM_MNIST_PATH):\n","    th.manual_seed(0)\n","    random.seed(0)\n","\n","    ddpm = DDPM(betas=get_beta_schedule(T), model=model, clip_x0=True)\n","    dataloader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    train_model(\n","        ddpm=ddpm,\n","        dataloader=dataloader,\n","        lr=LR,\n","        weight_decay=WEIGHT_DECAY,\n","        n_iters=N_ITERS,\n","        device=device\n","    )\n","    th.save(ddpm.to(\"cpu\").state_dict(), SAVE_DPPM_MNIST_PATH)\n","else:\n","    ddpm = DDPM.from_pretrained(model, SAVE_DPPM_MNIST_PATH)\n","\n","_ = ddpm.to(device)"]},{"cell_type":"markdown","metadata":{"id":"yPUwT3RYKYkO"},"source":["Let's draw some samples with the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbzi3EgUKYkP"},"outputs":[],"source":["num_samples = 16\n","ys = th.randint(10, size=(num_samples,), device=device)\n","Xs, ys = ddpm.sample(y=ys)\n","show_images(Xs, ys)"]},{"cell_type":"markdown","metadata":{"id":"b5rbPI8f0ZFy"},"source":["## Faster sampling with DDPM"]},{"cell_type":"markdown","metadata":{"id":"f0BDdrS9lKtw"},"source":["In the previous task it took us about 7 seconds to generate a batch of images with our diffusion model (even using a gpu).\n","\n","That's not a big deal for now. But the larger images in our dataset the more time is required for sampling (by a large factor).\n","\n","And this drawback of diffusion models can't be resolved generally with using more gpus, since it requires iterative sampling (in the previous task we consequently infered our model 1000 times).\n","\n","There are several techniques to alleviate this drawback.\n","\n","We are going to implement one of them, which was proposed [here](https://arxiv.org/abs/2102.09672)."]},{"cell_type":"markdown","metadata":{"id":"e0mUby7dkqMZ"},"source":["So, assume we have already trained a model to \"reverse\" a Markov chain of length T.\n","\n","Let's imagine, that it corresponds to a shorter Markov chain\n","$\\{S_0 = 0, S_1, \\ldots, S_{T'-1}, S_{T'} = T\\}$, where $T' < T$.\n","\n","Then in order to generate samples, we are to do $T' (< T)$ inferences of our model instead of T."]},{"cell_type":"markdown","metadata":{"id":"fo2X_E5ylJrR"},"source":["The only thing we are to make sure about is that $q^{new}(x_i) = q(x_{S_i})$.\n","\n","That's condition is satysfied if $q^{new}(x_i | x_0) = q(x_{S_i} | x_0)$.\n","\n","From that condition we can get betas for the new (the shorter one) diffusion process\n","$$\n","    \\begin{align}\n","        \\beta_i^{new} = 1 - \\frac{\n","            \\bar{\\alpha}_{S_i}\n","        }{\n","            \\bar{\\alpha}_{S_{i-1}}\n","        }\n","    \\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"WQLWgJr0KYkR"},"source":["Since diffusion model is fully describes by betas, we don't have to change anything in the sampling process.\n","\n","Though we have to slightly adjust pretrained model $\\epsilon$ inputs:\n","instead of $\\epsilon(x_i, i)$ (where $i$ is a timestep for the new diffusion process) we have to use $\\epsilon(x_i, S_i)$."]},{"cell_type":"markdown","metadata":{"id":"Oa4V-jHFKYkR"},"source":["You are to fill in the gaps marked with `you code`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4gadQO2KYkS"},"outputs":[],"source":["class SpacedDDPM(DDPM):\n","    \"\"\"\n","    A diffusion process which can skip steps in a base diffusion process.\n","\n","    :param use_timesteps: a collection (sequence or set) of timesteps from the\n","                          original diffusion process to retain.\n","    :param kwargs: the kwargs to create the base diffusion process.\n","    \"\"\"\n","\n","    def __init__(self, use_timesteps: Optional[Tuple]=None, **kwargs):\n","        if use_timesteps is None:\n","            use_timesteps = list(range(len(kwargs[\"betas\"])))\n","        self.use_timesteps = set(use_timesteps)\n","        timestep_map = []\n","        original_num_steps = len(kwargs[\"betas\"])\n","\n","        base_kwargs = deepcopy(kwargs)\n","        base_ddpm = DDPM(**base_kwargs)\n","        last_alpha_cumprod = 1.0\n","        new_betas = []\n","        for i, alpha_cumprod in enumerate(base_ddpm.forward_diffusion.alphas_cumprod):\n","            if i in self.use_timesteps:\n","                # ====\n","                # your code\n","                # 1) update new_betas (use equation (1))\n","                # 2) update timestep_map (it is a mapping S: i -> S_i)\n","                ...\n","                # ====\n","        kwargs[\"betas\"] = th.tensor(new_betas)\n","        kwargs[\"model\"] = _WrappedModel(kwargs[\"model\"], timestep_map)\n","        super().__init__(**kwargs)\n","\n","    @classmethod\n","    def from_pretrained(cls, *args, use_timesteps: Optional[Tuple]=None, **kwargs):\n","        ddpm = DDPM.from_pretrained(*args, **kwargs)\n","        return cls(\n","            use_timesteps = use_timesteps,\n","            betas = ddpm.betas,\n","            model = ddpm.model,\n","            clip_x0 = ddpm.clip_x0,\n","            shape = ddpm.shape,\n","            update_ema_after = ddpm.update_ema_after,\n","        )\n","\n","class _WrappedModel(nn.Module):\n","    def __init__(self, model: nn.Module, timestep_map: List):\n","        super().__init__()\n","        self.model = model\n","        self.timestep_map = timestep_map\n","\n","    @property\n","    def device(self):\n","        return next(self.model.parameters()).device\n","\n","    def __call__(self, x: th.Tensor, t: th.Tensor, *args, **kwargs) -> th.Tensor:\n","        # ====\n","        # your code\n","        # compute new_t using self.timestep_map\n","        new_t = ...\n","        # ====\n","        return self.model(x, new_t, *args, **kwargs)"]},{"cell_type":"markdown","metadata":{"id":"u5kuyfAiKYkT"},"source":["Let's apply it to our datasets"]},{"cell_type":"markdown","metadata":{"id":"eaMagRe4KYkU"},"source":["### Swiss Roll"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scc9m0-iKYkU"},"outputs":[],"source":["assert os.path.exists(SAVE_DPPM_SWISS_PATH)\n","T = 100\n","model = ConditionalMLP(d_in=2, T=T, n_classes=2)\n","device = \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NG2C66xIKYkU"},"outputs":[],"source":["for num_timesteps in [100, 50, 25, 10]:\n","    use_timesteps = np.linspace(1, T, num=num_timesteps).astype(\"int\")\n","    spaced_ddpm = SpacedDDPM.from_pretrained(\n","        use_timesteps=use_timesteps, model=model, ckpt_path=SAVE_DPPM_SWISS_PATH\n","    )\n","    _ = spaced_ddpm.to(device)\n","\n","    num_samples = 2000\n","    ys = th.randint(0, 2, size=(num_samples,), device=device)\n","    Xs, ys = spaced_ddpm.sample(ys)\n","\n","    plt.figure(figsize=(4, 4))\n","    sns.scatterplot(x=Xs[:, 0], y=Xs[:, 1], hue=ys)\n","    plt.title(f\"{num_timesteps = }/100\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ifW_LrmtKYkV"},"source":["### MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIDMcziDQZmi"},"outputs":[],"source":["# Downloading pretrained model\n","!gdown -O \"models/ddpm_mnist.pt\" \"https://drive.google.com/uc?id=1fSPB08M6aBNmhjRgSn3qpdq5hXl1Xhao\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80UQLPD2KYkV"},"outputs":[],"source":["assert os.path.exists(SAVE_DPPM_MNIST_PATH)\n","T = 1000\n","model = MyUNet()\n","device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9zZ2FPDKYkV"},"outputs":[],"source":["num_timesteps = 100\n","use_timesteps = np.linspace(1, T, num=num_timesteps).astype(\"int\")\n","spaced_ddpm = SpacedDDPM.from_pretrained(\n","    use_timesteps=use_timesteps, model=model, ckpt_path=SAVE_DPPM_MNIST_PATH\n",")\n","_ = spaced_ddpm.to(device)\n","\n","num_samples = 16\n","ys = th.randint(2, size=(num_samples,), device=device)\n","Xs, ys = spaced_ddpm.sample(y=ys)\n","show_images(Xs, ys)"]},{"cell_type":"markdown","metadata":{"id":"aMqCprHZKYkW"},"source":["## Classifier-free guidance"]},{"cell_type":"markdown","metadata":{"id":"zLXmc1qiKYkW"},"source":["We are able to generate samples relevant to given label by feeding the model this label as an input.\n","\n","First of all, there is not guarantees that we will get something relevant.\n","\n","Secondly, there is no handle to increase/decrease influence of a label.\n","\n","Now we are going to implement a technique reducing these drawbacks."]},{"cell_type":"markdown","metadata":{"id":"JFahhiYGKYkW"},"source":["Quick reminder of the method.\n","\n","Diffusion Models implicitly learn score-functions of marginal distributions $q(x_t)$ and sample from them.\n","\n","Let's make them sample from $q(x_t | y) = \\frac{q(y | x_t) q(x_t)}{q(y)}$."]},{"cell_type":"markdown","metadata":{"id":"05O3a8bcKYkW"},"source":["From that we have:\n","$\n","    \\nabla_{x_t} \\log q(x_t | y)\n","    =\n","    \\nabla_{x_t} \\log q(y | x_t)\n","    +\n","    \\nabla_{x_t} \\log q(x_t)\n","$"]},{"cell_type":"markdown","metadata":{"id":"a5MT-smbKYkX"},"source":["In order to increase label influence, we scale first additive:\n","$$\n","    \\nabla_{x_t} \\log q(x_t | y)\n","    =\n","    s \\cdot \\nabla_{x_t} \\log q(y | x_t)\n","    +\n","    \\nabla_{x_t} \\log q(x_t)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"qSIQRA1jKYkX"},"source":["Using score-model parametrization of diffusion models, we can approximate the aforementined conditional score-function with noise model:\n","$$\n","    -\\frac{\\hat{\\epsilon}_\\theta (x_t, y)}{\\sqrt{1 - \\bar{\\alpha}_t}}\n","    =\n","    -s \\cdot \\frac{\\epsilon_\\theta (x_t, y) - \\epsilon_\\theta (x_t, \\varnothing)}{\\sqrt{1 - \\bar{\\alpha}_t}}\n","    -\\frac{\\epsilon_\\theta (x_t, \\varnothing)}{\\sqrt{1 - \\bar{\\alpha}_t}}\n","$$\n","where $\\epsilon_\\theta (x_t, \\varnothing)$ is an unconditional diffusion model."]},{"cell_type":"markdown","metadata":{"id":"bCjVM0x1KYkX"},"source":["As a result we have\n","$$\n","    \\begin{align}\n","        \\hat{\\epsilon}_\\theta (x_t, y)\n","        &=\n","        s \\cdot (\\epsilon_\\theta (x_t, y) - \\epsilon_\\theta (x_t, \\varnothing))\n","        +\n","        \\epsilon_\\theta (x_t, \\varnothing)\\\\\n","        \\hat{\\epsilon}_\\theta (x_t, y)\n","        &=\n","        \\epsilon_\\theta (x_t, \\varnothing) \\cdot (1 - s)\n","        + \\epsilon_\\theta (x_t, y) \\cdot s\n","    \\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"5kZsx3uAKYkX"},"source":["Usually unconditional and conditional models are actually a one model.\n","\n","In this case `null_label` is considered as an actual label not equal to any others."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DvwPTOMaKYkY"},"outputs":[],"source":["class DDPM_CFG(SpacedDDPM):\n","    @th.no_grad()\n","    def sample(\n","        self, y: th.Tensor, guidance_scale: float=0., null_label: int=2\n","    ):\n","        assert self.shape is not None\n","        num_samples = y.shape[0]\n","        x = th.randn((num_samples, *self.shape), device=self.device, dtype=th.float32)\n","        indices = list(range(self.num_timesteps))[::-1]\n","\n","        for i in tqdm(indices):\n","            t = th.tensor([i] * num_samples, device=x.device)\n","            # ====\n","            # your code\n","            # 1) get epsilon with hat using the model\n","            # 2) sample from the reverse diffusion\n","            eps_hat = self._predict_eps_hat(x, t, guidance_scale, null_label)\n","            x = ...\n","            # ====\n","        return x, y\n","\n","    def _predict_eps_hat(\n","        self, x: th.Tensor, t: th.Tensor, y: th.Tensor, guidance_scale: float, null_label: int\n","    ):\n","        null_y = null_label * th.ones_like(y)\n","\n","        if self.ema_counter < self.update_ema_after:\n","            model = self.model\n","        else:\n","            model = self.ema\n","\n","        # ====\n","        # your code\n","        # get epsilon with hat using the model (use equation (2))\n","        return ...\n","        # ===="]},{"cell_type":"markdown","metadata":{"id":"GSWlklN5KYkY"},"source":["### Swiss Roll"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mb1SUDuzKYkY"},"outputs":[],"source":["X, y = make_swiss_dataset(2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpnyA4ZiKYkZ"},"outputs":[],"source":["T = 100\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE = 1024\n","LR = 0.01\n","WEIGHT_DECAY = 0.0\n","N_ITERS = 15000\n","# ====\n","\n","model = ConditionalMLP(d_in=2, T=T, n_classes=2+1)\n","device = \"cpu\" # cpu is enough\n","\n","if not os.path.exists(SAVE_DPPM_CFG_SWISS_PATH):\n","    th.manual_seed(0)\n","    random.seed(0)\n","\n","    dataloader = get_labeled_data_loader(X, y, batch_size=BATCH_SIZE, shuffle=True, drop_label=0.4)\n","    ddpm = DDPM_CFG(betas=get_beta_schedule(T), model=model)\n","\n","    train_model(\n","        ddpm=ddpm,\n","        dataloader=dataloader,\n","        lr=LR,\n","        weight_decay=WEIGHT_DECAY,\n","        n_iters=N_ITERS,\n","        device=device\n","    )\n","    th.save(ddpm.to(\"cpu\").state_dict(), SAVE_DPPM_CFG_SWISS_PATH)\n","else:\n","    ddpm = DDPM_CFG.from_pretrained(model=model, ckpt_path=SAVE_DPPM_CFG_SWISS_PATH)\n","\n","_ = ddpm.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PnXyM9UKYkZ"},"outputs":[],"source":["num_samples = X.shape[0]\n","ys = th.randint(0, 2, size=(num_samples,), device=device)\n","for guidance_scale in [0.0, 0.5, 1.0, 2.0, 3.0]:\n","    Xs, ys = ddpm.sample(ys, guidance_scale=guidance_scale, null_label=2)\n","    plt.figure(figsize=(4, 4))\n","    sns.scatterplot(x=Xs[:, 0], y=Xs[:, 1], hue=ys)\n","    plt.title(f\"{guidance_scale = }\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XONYtuv5KYka"},"outputs":[],"source":["num_timesteps = 50\n","use_timesteps = np.linspace(1, T, num=num_timesteps).astype(\"int\")\n","ddpm = DDPM_CFG.from_pretrained(\n","    use_timesteps=use_timesteps, model=model, ckpt_path=SAVE_DPPM_CFG_SWISS_PATH\n",")\n","ddpm.to(device)\n","\n","num_samples = X.shape[0]\n","ys = th.randint(0, 2, size=(num_samples,), device=device)\n","for guidance_scale in [0.0, 0.5, 1.0, 2.0, 3.0]:\n","    Xs, ys = ddpm.sample(ys, guidance_scale=guidance_scale, null_label=2)\n","    plt.figure(figsize=(4, 4))\n","    sns.scatterplot(x=Xs[:, 0], y=Xs[:, 1], hue=ys)\n","    plt.title(f\"{guidance_scale = }\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"U9zrumEtKYka"},"source":["### MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pkw_khvlKYkb"},"outputs":[],"source":["def show_images(images, ys, title=\"\"):\n","    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n","\n","    # Converting images to CPU numpy arrays\n","    if type(images) is th.Tensor:\n","        images = images.detach().cpu().numpy()\n","        ys = ys.detach().cpu().numpy()\n","\n","    # Defining number of rows and columns\n","    rows = int(len(images) ** (1 / 2))\n","    cols = round(len(images) / rows)\n","    fig = plt.figure(figsize=(cols*2, rows*2))\n","\n","    # Populating figure with sub-plots\n","    idx = 0\n","    for r in range(rows):\n","        for c in range(cols):\n","            fig.add_subplot(rows, cols, idx + 1)\n","\n","            if idx < len(images):\n","                plt.imshow(images[idx][0], cmap=\"gray\")\n","                plt.title(f\"{int(ys[idx])}\")\n","                plt.tick_params(bottom = False, labelbottom=False)\n","                idx += 1\n","    fig.suptitle(title, fontsize=30)\n","\n","    # Showing the figure\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPOcs07fKYkc"},"outputs":[],"source":["from torchvision.datasets.mnist import MNIST\n","\n","def mnist_to_train_range(X):\n","    return ((X.astype(\"float32\") / 255.) - 0.5) * 2\n","\n","def mnist_from_train_range(X):\n","    return (((X.astype(\"float32\") + 1.0) / 2) * 255.).astype(\"int\")\n","\n","dataset = MNIST(\"./datasets\", download=True, train=True)\n","X = dataset.data.numpy().astype(\"float32\")[:, None]\n","y = dataset.targets.numpy()\n","mnist_loader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZRcDMTHQn0x"},"outputs":[],"source":["# Downloading pretrained model\n","!gdown -O \"models/ddpm_cfg_mnist.pt\" \"https://drive.google.com/uc?id=1DoLq4PYoef5fo-tewy22o5P89no5V6NW\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huBngtN2KYkc"},"outputs":[],"source":["T = 1000\n","# ====\n","# your code\n","# choose these parameters\n","BATCH_SIZE = 1024\n","LR = 0.01\n","WEIGHT_DECAY = 0.0\n","N_ITERS = 5000\n","# ====\n","\n","model = MyUNet(use_null_cond=True)\n","device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n","\n","if not os.path.exists(SAVE_DPPM_CFG_MNIST_PATH):\n","    th.manual_seed(0)\n","    np.random.seed(0)\n","    random.seed(0)\n","\n","    ddpm = DDPM_CFG(betas=get_beta_schedule(T), model=model, clip_x0=True)\n","    dataloader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=BATCH_SIZE, shuffle=True, drop_label=0.4)\n","\n","    train_model(\n","        ddpm=ddpm,\n","        dataloader=dataloader,\n","        lr=LR,\n","        weight_decay=WEIGHT_DECAY,\n","        n_iters=N_ITERS,\n","        device=device\n","    )\n","    th.save(ddpm.to(\"cpu\").state_dict(), SAVE_DPPM_CFG_MNIST_PATH)\n","else:\n","    num_timesteps = 100\n","    use_timesteps = np.linspace(1, T, num=num_timesteps).astype(\"int\")\n","    ddpm = DDPM_CFG.from_pretrained(use_timesteps=use_timesteps, model=model, ckpt_path=SAVE_DPPM_CFG_MNIST_PATH)\n","\n","_ = ddpm.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u46KBoIhKYkc"},"outputs":[],"source":["num_samples = 16\n","ys = th.randint(10, size=(num_samples,), device=device)\n","Xs, ys = ddpm.sample(ys, guidance_scale=1.0, null_label=10)\n","show_images(Xs, ys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYUofKnkKYkd"},"outputs":[],"source":["num_samples = 16\n","ys = th.randint(10, size=(num_samples,), device=device)\n","Xs, ys = ddpm.sample(ys, guidance_scale=5.0, null_label=10)\n","show_images(Xs, ys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIxTpzQFKYkd"},"outputs":[],"source":["num_samples = 16\n","ys = th.randint(10, size=(num_samples,), device=device)\n","Xs, ys = ddpm.sample(ys, guidance_scale=0.0, null_label=10)\n","show_images(Xs, ys)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
